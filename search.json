[
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "reference/missing_summary.html",
    "href": "reference/missing_summary.html",
    "title": "missing_summary",
    "section": "",
    "text": "missing_summary\n\n\n\n\n\nName\nDescription\n\n\n\n\nmissing_summary\nGenerate a summary of missing values in a dataset.\n\n\n\n\n\nmissing_summary.missing_summary(data)\nGenerate a summary of missing values in a dataset.\nThis function computes, for each column in a pandas DataFrame, the total number of missing values and the proportion of missing values relative to the number of rows.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nInput dataset to be analyzed.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA summary table indexed by column name with: - missing_count (int): number of missing values per column - missing_pct (float): proportion of missing values per column\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nValueError\nIf data is None or an empty DataFrame.\n\n\n\nTypeError\nIf data is not a pandas DataFrame.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from ez_df_data_validator.missing_summary import missing_summary\n&gt;&gt;&gt; df = pd.DataFrame({\"a\": [1, None, 3], \"b\": [None, None, \"x\"]})\n&gt;&gt;&gt; missing_summary(df)\n        missing_count  missing_pct\ncolumn\na                   1     0.333333\nb                   2     0.666667"
  },
  {
    "objectID": "reference/missing_summary.html#functions",
    "href": "reference/missing_summary.html#functions",
    "title": "missing_summary",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nmissing_summary\nGenerate a summary of missing values in a dataset.\n\n\n\n\n\nmissing_summary.missing_summary(data)\nGenerate a summary of missing values in a dataset.\nThis function computes, for each column in a pandas DataFrame, the total number of missing values and the proportion of missing values relative to the number of rows.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nInput dataset to be analyzed.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA summary table indexed by column name with: - missing_count (int): number of missing values per column - missing_pct (float): proportion of missing values per column\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nValueError\nIf data is None or an empty DataFrame.\n\n\n\nTypeError\nIf data is not a pandas DataFrame.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from ez_df_data_validator.missing_summary import missing_summary\n&gt;&gt;&gt; df = pd.DataFrame({\"a\": [1, None, 3], \"b\": [None, None, \"x\"]})\n&gt;&gt;&gt; missing_summary(df)\n        missing_count  missing_pct\ncolumn\na                   1     0.333333\nb                   2     0.666667"
  },
  {
    "objectID": "reference/handle_missing.html",
    "href": "reference/handle_missing.html",
    "title": "handle_missing",
    "section": "",
    "text": "handle_missing\n\n\n\n\n\nName\nDescription\n\n\n\n\nhandle_missing\nHandles missing data in a pandas DataFrame.\n\n\n\n\n\nhandle_missing.handle_missing(df, strategy='drop', columns=None)\nHandles missing data in a pandas DataFrame.\nFunction returns a pandas DataFrame where missing values are handled in a user-defined way.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame\nrequired\n\n\nstrategy\nstr\nThe strategy to use for handling missing values. Permissible values (numeric): mean, median, max, min, mode, drop Permissible values (else): mode, drop\n'drop'\n\n\ncolumns\nlist\nColumns where the missing values are to be handled. Default handles all columns.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nDataframe where missing values have been handled.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a pandas DataFrame. If strategy is not a string. If columns is not a list or None. If strategy cannot be used for dtype of column. If dtype of column is not designed to be handled.\n\n\n\nValueError\nIf strategy is not permitted. If column is not in df.columns. If column only contains NaN.\n\n\n\n\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;df = pd.DataFrame({\n...     \"A\": [1, 1, 2],\n...     \"B\": [np.nan, 3, 4]\n... })\n&gt;&gt;&gt; handle_missing(df)\n   A  B\n1  1  3\n2  2  4\n&gt;&gt;&gt; handle_missing(df, strategy='mean')\n   A  B\n0  1  3.5\n1  1  3.0\n2  2  4.0"
  },
  {
    "objectID": "reference/handle_missing.html#functions",
    "href": "reference/handle_missing.html#functions",
    "title": "handle_missing",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nhandle_missing\nHandles missing data in a pandas DataFrame.\n\n\n\n\n\nhandle_missing.handle_missing(df, strategy='drop', columns=None)\nHandles missing data in a pandas DataFrame.\nFunction returns a pandas DataFrame where missing values are handled in a user-defined way.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nInput DataFrame\nrequired\n\n\nstrategy\nstr\nThe strategy to use for handling missing values. Permissible values (numeric): mean, median, max, min, mode, drop Permissible values (else): mode, drop\n'drop'\n\n\ncolumns\nlist\nColumns where the missing values are to be handled. Default handles all columns.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nDataframe where missing values have been handled.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a pandas DataFrame. If strategy is not a string. If columns is not a list or None. If strategy cannot be used for dtype of column. If dtype of column is not designed to be handled.\n\n\n\nValueError\nIf strategy is not permitted. If column is not in df.columns. If column only contains NaN.\n\n\n\n\n\n\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;df = pd.DataFrame({\n...     \"A\": [1, 1, 2],\n...     \"B\": [np.nan, 3, 4]\n... })\n&gt;&gt;&gt; handle_missing(df)\n   A  B\n1  1  3\n2  2  4\n&gt;&gt;&gt; handle_missing(df, strategy='mean')\n   A  B\n0  1  3.5\n1  1  3.0\n2  2  4.0"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "API Reference\n\n\n\nstandardize_schema\nSanitize and standardize a DataFrames structure.\n\n\nfind_duplicates\n\n\n\nhandle_missing\n\n\n\nmissing_summary"
  },
  {
    "objectID": "reference/index.html#functions",
    "href": "reference/index.html#functions",
    "title": "Function reference",
    "section": "",
    "text": "API Reference\n\n\n\nstandardize_schema\nSanitize and standardize a DataFrames structure.\n\n\nfind_duplicates\n\n\n\nhandle_missing\n\n\n\nmissing_summary"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "Contributions of all kinds are welcome here, and they are greatly appreciated! Every little bit helps, and credit will always be given.\n\n\nYou can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/Nish-kumar/dsci_524_group23/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nDSCI_524_group23 could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/Nish-kumar/dsci_524_group23/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time.\n\n\n\n\nReady to contribute? Here’s how to set up DSCI_524_group23 for local development.\n\nFork the https://github.com/Nish-kumar/dsci_524_group23 repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/dsci_524_group23.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CONTRIBUTING.html#example-contributions",
    "href": "CONTRIBUTING.html#example-contributions",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/Nish-kumar/dsci_524_group23/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nDSCI_524_group23 could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/Nish-kumar/dsci_524_group23/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time."
  },
  {
    "objectID": "CONTRIBUTING.html#get-started",
    "href": "CONTRIBUTING.html#get-started",
    "title": "Contributing",
    "section": "",
    "text": "Ready to contribute? Here’s how to set up DSCI_524_group23 for local development.\n\nFork the https://github.com/Nish-kumar/dsci_524_group23 repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/dsci_524_group23.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.\n\n\n\n\n\nTools & infrastructure reflection page added to documentation website (tools_infrastructure.qmd) and linked in the navbar (#86).\nExample output added to the tutorial for clearer function usage.\nDocstrings added to core unit tests to improve documentation clarity (#78).\nAdditional CHANGELOG entries to improve release tracking (#99).\n\n\n\n\n\nDocumentation structure and layout improved.\nREADME badges updated to use dynamic versioning.\npublish.yml and pyproject.toml updated to support dynamic versioning and TestPyPI publishing.\nBuild workflow updated to generate documentation preview deployments (#94).\n\n\n\n\n\nFixed missing output for example code in the README (#83, #92).\nFixed documentation landing page layout.\nRemoved unnecessary generated files from the repository (#85).\n\n\n\n\n\nGitHub Actions workflows updated to:\n\nrun pytest with coverage\nrun ruff lint checks\nbuild Quartodoc reference\nrender Quarto documentation\ndeploy documentation previews\npublish package to TestPyPI via automated pipeline\n\nDevelopment → main branch sync completed following staging workflow.\n\n\n\n\n\n\n\n\nMore test handle missing (#62)\nAdd missing_summary function and unit tests (#43)\nAdd ruff to toml (#59)\nAdd CI workflow and improve missing_summary docs and tests (#52)\nbuild.yml (#66)\nChange package name (#67)\nUpdate README for Milestone 3 (docs, CI, usage, tests) (#70)\nPublish pipeline to TestPYPI (#71)\n\n\n\n\n\n\n\n\nAdd missing_summary function implementation and unit tests by @wst0712 in #43\nFix docstring in handle_missing() (#42)\nImplement schema_standardizer function (#40)\nFix and standardize docstrings across functions (#39)\nAdd implementation and unit tests for handle_missing() (LLM-assisted design - decisions) (#38)\nAdd function code for find_duplicates (#36)\nAdd unit tests for find_duplicates (#35)\nRefine function definitions based on LLM feedback (#34)\n\n\n\n\n\n\n\n\nInitial repo setup (#7)\nedit readme (#9)\ncreate function spec for find_duplicates (#10)\nAdd SchemaStandardizer for initial dataframe hygiene (#11)\nHandle missing (#14)\nAdd missing_summary function specification (#12)\nUpdate README with missing_summary function details (#15)\nFormat readme (#16)"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog",
    "section": "",
    "text": "Tools & infrastructure reflection page added to documentation website (tools_infrastructure.qmd) and linked in the navbar (#86).\nExample output added to the tutorial for clearer function usage.\nDocstrings added to core unit tests to improve documentation clarity (#78).\nAdditional CHANGELOG entries to improve release tracking (#99).\n\n\n\n\n\nDocumentation structure and layout improved.\nREADME badges updated to use dynamic versioning.\npublish.yml and pyproject.toml updated to support dynamic versioning and TestPyPI publishing.\nBuild workflow updated to generate documentation preview deployments (#94).\n\n\n\n\n\nFixed missing output for example code in the README (#83, #92).\nFixed documentation landing page layout.\nRemoved unnecessary generated files from the repository (#85).\n\n\n\n\n\nGitHub Actions workflows updated to:\n\nrun pytest with coverage\nrun ruff lint checks\nbuild Quartodoc reference\nrender Quarto documentation\ndeploy documentation previews\npublish package to TestPyPI via automated pipeline\n\nDevelopment → main branch sync completed following staging workflow."
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "More test handle missing (#62)\nAdd missing_summary function and unit tests (#43)\nAdd ruff to toml (#59)\nAdd CI workflow and improve missing_summary docs and tests (#52)\nbuild.yml (#66)\nChange package name (#67)\nUpdate README for Milestone 3 (docs, CI, usage, tests) (#70)\nPublish pipeline to TestPYPI (#71)"
  },
  {
    "objectID": "CHANGELOG.html#section-1",
    "href": "CHANGELOG.html#section-1",
    "title": "Changelog",
    "section": "",
    "text": "Add missing_summary function implementation and unit tests by @wst0712 in #43\nFix docstring in handle_missing() (#42)\nImplement schema_standardizer function (#40)\nFix and standardize docstrings across functions (#39)\nAdd implementation and unit tests for handle_missing() (LLM-assisted design - decisions) (#38)\nAdd function code for find_duplicates (#36)\nAdd unit tests for find_duplicates (#35)\nRefine function definitions based on LLM feedback (#34)"
  },
  {
    "objectID": "CHANGELOG.html#section-2",
    "href": "CHANGELOG.html#section-2",
    "title": "Changelog",
    "section": "",
    "text": "Initial repo setup (#7)\nedit readme (#9)\ncreate function spec for find_duplicates (#10)\nAdd SchemaStandardizer for initial dataframe hygiene (#11)\nHandle missing (#14)\nAdd missing_summary function specification (#12)\nUpdate README with missing_summary function details (#15)\nFormat readme (#16)"
  },
  {
    "objectID": "DEVELOPMENT.html",
    "href": "DEVELOPMENT.html",
    "title": "Development Guide",
    "section": "",
    "text": "Welcome to your shiny new package. This page will help you get started with using Hatch to manage your package.\nIf you look at your project, you will see that a pyproject.toml file. This file stores both your package configuration and settings for development tools like Hatch that you will use to work on your package.\nThis file is written using a .toml format. You can learn more about toml here. Here’s the TL&DR:\n\nEach [] section in the toml file is called a table.\nYou can nest tables with double brackets like this[[]]\nTables contain information about a element that you want to configure.\n\nWe are using Hatch as the default packaging tool. Hatch allows you to configure and run environments and scripts similar to workflow tools like tox or nox.\nHach, by default, uses virtual environments (venv) to manage environments. But you can configure it to use other environment tools.Read the hatch documentation to learn more about environments.\nFor this template, we have set up Hatch environments for you to use. At the bottom of your pyproject.toml file, notice a hatch environment section that looks like this:\n########################################\n# Hatch Environments\n########################################\nBelow is the Hatch environment to install your package. Notice that it defines pip and twine as two packages that the environment needs.\n[tool.hatch.envs.build]\ndescription = \"\"\"Test the installation the package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\nThe table below defines the scripts that you will run build and check your package.\n[tool.hatch.envs.build.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\ndetached = true\nYou can enter that environment to check it out:\n$ hatch shell build\nIf you run pip list, in the environment, twine will be there:\n$ pip list\nHatch by default, installs your package in editable mode (-e) into its virtual environments. But if detached=True is set, then it will skip installing your package into the virtual enviornment.\n\n\nBelow you see the Hatch environment test table.\ntool.hatch.envs says, “Hey, Hatch, this is the definition for an environment.” test is the name of the environment.\nThe environment below defines the dependencies that Hatch needs to install into the environment named test.\n[tool.hatch.envs.test]\ndescription = \"\"\"Run the test suite.\"\"\"\ndependencies = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-raises\",\n    \"pytest-randomly\",\n    \"pytest-xdist\",\n]\nTo enter a Hatch environment use:\nhatch shell environmentname\nSo you can enter the test environment above with:\nhatch shell test\n\n\n\nIf the environment has a matrix associated with it, that tells Hatch to run the test scripts across different Python versions.\n[[tool.hatch.envs.test.matrix]]\npython = [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\nIf you run hatch shell test, you will see the output below. To enter an environment with a matrix attached to it, you need to pick the Python environment version that you want to open.\n$ hatch shell test                           \nEnvironment `test` defines a matrix, choose one of the following instead:\n\ntest.py3.10\ntest.py3.11\ntest.py3.12\ntest.py3.13\nOpen the Python 3.13 environment like this:\n$ hatch shell test.py3.13\nTo leave an environment use:\n$ deactivate\n\n\n\nIn the tests section of your pyproject.toml, you will see a tool.hatch.envs.test.scripts table.\nThis table defines the commands that you want Hatch to run in the test environment. Notice that the script has one command called run.\n[tool.hatch.envs.test.scripts]\nrun = \"pytest {args:--cov=greatproject --cov-report=term-missing}\"\nTo run this script , use:\nhatch run test:run\n\nhatch run: calls Hatch and tells it that it will be running a command\ntest:run: defines the environment you want it to run (test) and defines the name of the “script” to berun.\n\nIf you have a Hatch matrix setup for tests, it will both install the necessary Python version using UV and run your tests on each version of the Python versions that you declare in the matrix table. In this case, there are 4 Python versions in the environment, so your tests will run 4 times, once in each Python version listed in the matrix table.\n@lwasser ➜ /workspaces/pyopensci-scipy25-create-python-package (main) $ hatch run test:run\n──────────────────────────────────────────────────────────────────────── test.py3.10 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.10.16, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1490740387\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.10.16-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n──────────────────────────────────────────────────────────────────────── test.py3.11 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.11.12, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1596865075\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.11.12-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n\n\n\nYou can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "DEVELOPMENT.html#build-your-package",
    "href": "DEVELOPMENT.html#build-your-package",
    "title": "Development Guide",
    "section": "",
    "text": "You can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Package\n\n\n\n\n\n\nez-df-data-validator is a project that provides basic, but essential data cleaning functionality for ML workflows. This package provides a lightweight and user friendly toolkit for common data cleaning tasks in Python. It is designed to streamline data preprocessing by offering clear, reusable functions for detecting duplicates, standardizing column names, and handling missing values. The goal is to reduce repetitive code and make data preparation more efficient and reproducible.\n\n\n\nInstall for regular use:\nCreate a new folder using mkdir test_ez and run the below command:\npip install -i https://test.pypi.org/simple/ ez-df-data-validator\n\n\n\nPython 3.10+\n\n\n\n\nWithin the test_ez folder, create a test file using touch test_package.py. Copy the below contents into this newly created file.\nimport pandas as pd\nimport numpy as np\nfrom ez_df_data_validator import (\n    standardize_schema, \n    missing_summary, \n    handle_missing,\n    find_duplicates\n)\n\n# Create a messy dataset\ndf = pd.DataFrame({\n    \"Age \": [25, 25, 30, np.nan],\n    \"Income($)\": [50000, 50000, 60000, 60000],\n    \"City\": [\"Van\", \"Van\", \"Tor\", \"Tor\"]\n})\n\n# Clean headers\ndf = standardize_schema(df)\n\n# Check for duplicates\nduplicates = find_duplicates(df)\nprint(f\"Found {len(duplicates)} duplicate rows\")\n\n# Summarize missing values\nprint(missing_summary(df))\n\n# Handle missing values\ndf_clean = handle_missing(df, strategy=\"drop\")\nRun the script with python test_package.py. It should show an output similar to:\n$ python test_package.py\nFound 1 duplicate rows\n        missing_count  missing_pct\ncolumn                            \nage                 1         0.25\nincome              0         0.00\ncity                0         0.00\n\n\n\n\nThe package provides the following core data validation and cleaning utilities:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nstandardize_schema()\nStandardize DataFrame column headers, remove duplicate columns and drop constant columns.\n\n\nfind_duplicates()\nIdentifies duplicate rows in a dataset based on one or more specified columns, helping users quickly detect and inspect redundant data.\n\n\nhandle_missing()\nHandles missing data in input Pandas dataframe so as to speed up the data science pipeline.\n\n\nmissing_summary()\nSummarizes missing values per column (count and proportion) to help assess data completeness.\n\n\n\n\n\n\nFollow these steps to set up the development environment and contribute to the project.\nWe use conda to manage dependencies.\n# Create and activate environment\nconda env create -f environment.yml\nconda activate ez_df_data_validator\n\n# Install package with development + testing + docs tools\npip install -e \".[tests,dev,docs]\"\n\n# Run tests\npytest\npytest --cov=ez_df_data_validator --cov-report=term-missing --cov-branch\n\n# Build documentation locally\nquartodoc build\nquarto preview\n\n\n\nThis project uses GitHub Actions for automated testing and code quality checks.\nCI workflow includes:\n\nPython 3.12 environment\n\nEditable package installation with dev/test dependencies\n\nPytest with coverage reporting\n\nRuff linting\n\nWorkflows run on pushes and pull requests to main.\n\n\n\nProject documentation is automatically generated using quartodoc and deployed with GitHub Pages as part of the CI/CD workflow.\n\nProject Homepage\nAPI Reference\nTestPYPI Package\n\n\n\n\nThis package is intended to complement existing data science libraries rather than replace them. Core functionality overlaps with well established tools such as pandas and NumPy, which provide operations for data manipulation and cleaning. However, this package focuses on wrapping common data cleaning patterns into simple functions that are easy to use. Similar preprocessing utilities also exist in scikit-learn.\n\n\n\n\nCopyright © 2026 Nishanth Kumarasamy etc.\nFree software distributed under the MIT License.\n\n\n\n\n\nGaurang Ahuja\nNishanth Kumarasamy\nJohnson Leung\nSiting Wang"
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "ez-df-data-validator is a project that provides basic, but essential data cleaning functionality for ML workflows. This package provides a lightweight and user friendly toolkit for common data cleaning tasks in Python. It is designed to streamline data preprocessing by offering clear, reusable functions for detecting duplicates, standardizing column names, and handling missing values. The goal is to reduce repetitive code and make data preparation more efficient and reproducible."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Install for regular use:\nCreate a new folder using mkdir test_ez and run the below command:\npip install -i https://test.pypi.org/simple/ ez-df-data-validator\n\n\n\nPython 3.10+\n\n\n\n\nWithin the test_ez folder, create a test file using touch test_package.py. Copy the below contents into this newly created file.\nimport pandas as pd\nimport numpy as np\nfrom ez_df_data_validator import (\n    standardize_schema, \n    missing_summary, \n    handle_missing,\n    find_duplicates\n)\n\n# Create a messy dataset\ndf = pd.DataFrame({\n    \"Age \": [25, 25, 30, np.nan],\n    \"Income($)\": [50000, 50000, 60000, 60000],\n    \"City\": [\"Van\", \"Van\", \"Tor\", \"Tor\"]\n})\n\n# Clean headers\ndf = standardize_schema(df)\n\n# Check for duplicates\nduplicates = find_duplicates(df)\nprint(f\"Found {len(duplicates)} duplicate rows\")\n\n# Summarize missing values\nprint(missing_summary(df))\n\n# Handle missing values\ndf_clean = handle_missing(df, strategy=\"drop\")\nRun the script with python test_package.py. It should show an output similar to:\n$ python test_package.py\nFound 1 duplicate rows\n        missing_count  missing_pct\ncolumn                            \nage                 1         0.25\nincome              0         0.00\ncity                0         0.00"
  },
  {
    "objectID": "index.html#functions",
    "href": "index.html#functions",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "The package provides the following core data validation and cleaning utilities:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nstandardize_schema()\nStandardize DataFrame column headers, remove duplicate columns and drop constant columns.\n\n\nfind_duplicates()\nIdentifies duplicate rows in a dataset based on one or more specified columns, helping users quickly detect and inspect redundant data.\n\n\nhandle_missing()\nHandles missing data in input Pandas dataframe so as to speed up the data science pipeline.\n\n\nmissing_summary()\nSummarizes missing values per column (count and proportion) to help assess data completeness."
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Follow these steps to set up the development environment and contribute to the project.\nWe use conda to manage dependencies.\n# Create and activate environment\nconda env create -f environment.yml\nconda activate ez_df_data_validator\n\n# Install package with development + testing + docs tools\npip install -e \".[tests,dev,docs]\"\n\n# Run tests\npytest\npytest --cov=ez_df_data_validator --cov-report=term-missing --cov-branch\n\n# Build documentation locally\nquartodoc build\nquarto preview"
  },
  {
    "objectID": "index.html#continuous-integration",
    "href": "index.html#continuous-integration",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "This project uses GitHub Actions for automated testing and code quality checks.\nCI workflow includes:\n\nPython 3.12 environment\n\nEditable package installation with dev/test dependencies\n\nPytest with coverage reporting\n\nRuff linting\n\nWorkflows run on pushes and pull requests to main."
  },
  {
    "objectID": "index.html#documentation",
    "href": "index.html#documentation",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Project documentation is automatically generated using quartodoc and deployed with GitHub Pages as part of the CI/CD workflow.\n\nProject Homepage\nAPI Reference\nTestPYPI Package"
  },
  {
    "objectID": "index.html#position-of-this-package-in-the-python-ecosystem",
    "href": "index.html#position-of-this-package-in-the-python-ecosystem",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "This package is intended to complement existing data science libraries rather than replace them. Core functionality overlaps with well established tools such as pandas and NumPy, which provide operations for data manipulation and cleaning. However, this package focuses on wrapping common data cleaning patterns into simple functions that are easy to use. Similar preprocessing utilities also exist in scikit-learn."
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Copyright © 2026 Nishanth Kumarasamy etc.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "ez-df-data-validator",
    "section": "",
    "text": "Gaurang Ahuja\nNishanth Kumarasamy\nJohnson Leung\nSiting Wang"
  },
  {
    "objectID": "reference/find_duplicates.html",
    "href": "reference/find_duplicates.html",
    "title": "find_duplicates",
    "section": "",
    "text": "find_duplicates\n\n\n\n\n\nName\nDescription\n\n\n\n\nfind_duplicates\nIdentify duplicate rows in a pandas DataFrame.\n\n\n\n\n\nfind_duplicates.find_duplicates(data, subset=None, keep='first')\nIdentify duplicate rows in a pandas DataFrame.\nThis function returns the rows that are considered duplicates according to the specified subset of columns. Rows are considered duplicates if they have identical values across the specified columns, following pandas equality and NaN-handling semantics.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nInput DataFrame to check for duplicate rows.\nrequired\n\n\nsubset\nlist of str\nList of column names to consider when identifying duplicates. If None, all columns are used. All column names must exist in data, and the list must not be empty.\nNone\n\n\nkeep\n(first, last, False)\nDetermines which duplicates are returned: - ‘first’ : Return duplicates except for the first occurrence. - ‘last’ : Return duplicates except for the last occurrence. - False : Return all duplicate rows.\n'first'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA new DataFrame containing only the rows identified as duplicates, with the index reset to a default RangeIndex. If no duplicate rows are found, an empty DataFrame with the same columns as data is returned.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf data is not an instance of pandas.DataFrame. If subset is not None and is not a list of strings.\n\n\n\nValueError\nIf subset contains columns not present in data or if keep is not one of {‘first’, ‘last’, False}.\n\n\n\n\n\n\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"A\": [1, 1, 2],\n...     \"B\": [3, 3, 4]\n... })\n&gt;&gt;&gt; find_duplicates(df)\n   A  B\n1  1  3\n&gt;&gt;&gt; find_duplicates(df, keep=False)\n   A  B\n0  1  3\n1  1  3"
  },
  {
    "objectID": "reference/find_duplicates.html#functions",
    "href": "reference/find_duplicates.html#functions",
    "title": "find_duplicates",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nfind_duplicates\nIdentify duplicate rows in a pandas DataFrame.\n\n\n\n\n\nfind_duplicates.find_duplicates(data, subset=None, keep='first')\nIdentify duplicate rows in a pandas DataFrame.\nThis function returns the rows that are considered duplicates according to the specified subset of columns. Rows are considered duplicates if they have identical values across the specified columns, following pandas equality and NaN-handling semantics.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nInput DataFrame to check for duplicate rows.\nrequired\n\n\nsubset\nlist of str\nList of column names to consider when identifying duplicates. If None, all columns are used. All column names must exist in data, and the list must not be empty.\nNone\n\n\nkeep\n(first, last, False)\nDetermines which duplicates are returned: - ‘first’ : Return duplicates except for the first occurrence. - ‘last’ : Return duplicates except for the last occurrence. - False : Return all duplicate rows.\n'first'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA new DataFrame containing only the rows identified as duplicates, with the index reset to a default RangeIndex. If no duplicate rows are found, an empty DataFrame with the same columns as data is returned.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf data is not an instance of pandas.DataFrame. If subset is not None and is not a list of strings.\n\n\n\nValueError\nIf subset contains columns not present in data or if keep is not one of {‘first’, ‘last’, False}.\n\n\n\n\n\n\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"A\": [1, 1, 2],\n...     \"B\": [3, 3, 4]\n... })\n&gt;&gt;&gt; find_duplicates(df)\n   A  B\n1  1  3\n&gt;&gt;&gt; find_duplicates(df, keep=False)\n   A  B\n0  1  3\n1  1  3"
  },
  {
    "objectID": "reference/standardize_schema.html",
    "href": "reference/standardize_schema.html",
    "title": "standardize_schema",
    "section": "",
    "text": "standardize_schema(data)\nSanitize and standardize a DataFrames structure.\nThis function performs a series of cleaning steps: 1. Standardizes column headers (snake_case, no punctuation/replace with underscore). 2. Removes columns that result in duplicate names (keeping the first). 3. Removes columns containing a single unique value (constants).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nThe raw input DataFrame to be standardized.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nThe fully sanitized DataFrame.\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf the input data is not a pandas DataFrame.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"First Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n...     \"Age\": [25, 30, 35],\n...     \"age\": [25, 30, 35],\n...     \"Constant_Column\": [1, 1, 1],\n...     \"  Special@Char$ \": [100, 200, 300]\n... })\n&gt;&gt;&gt; standardized_df = standardize_schema(df)\n&gt;&gt;&gt; standardized_df\n  first_name  age  special_char\n0      Alice   25           100\n1        Bob   30           200\n2    Charlie   35           300"
  },
  {
    "objectID": "reference/standardize_schema.html#parameters",
    "href": "reference/standardize_schema.html#parameters",
    "title": "standardize_schema",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.DataFrame\nThe raw input DataFrame to be standardized.\nrequired"
  },
  {
    "objectID": "reference/standardize_schema.html#returns",
    "href": "reference/standardize_schema.html#returns",
    "title": "standardize_schema",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nThe fully sanitized DataFrame."
  },
  {
    "objectID": "reference/standardize_schema.html#raises",
    "href": "reference/standardize_schema.html#raises",
    "title": "standardize_schema",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nTypeError\nIf the input data is not a pandas DataFrame."
  },
  {
    "objectID": "reference/standardize_schema.html#examples",
    "href": "reference/standardize_schema.html#examples",
    "title": "standardize_schema",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"First Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n...     \"Age\": [25, 30, 35],\n...     \"age\": [25, 30, 35],\n...     \"Constant_Column\": [1, 1, 1],\n...     \"  Special@Char$ \": [100, 200, 300]\n... })\n&gt;&gt;&gt; standardized_df = standardize_schema(df)\n&gt;&gt;&gt; standardized_df\n  first_name  age  special_char\n0      Alice   25           100\n1        Bob   30           200\n2    Charlie   35           300"
  },
  {
    "objectID": "tools_infrastructure.html",
    "href": "tools_infrastructure.html",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "",
    "text": "In this project, we adopted modern software engineering practices to manage collaboration, ensure code quality, and automate testing, documentation, and release processes. The infrastructure we built mirrors real-world open-source Python projects and helped us understand how professional development workflows operate."
  },
  {
    "objectID": "tools_infrastructure.html#overview",
    "href": "tools_infrastructure.html#overview",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "",
    "text": "In this project, we adopted modern software engineering practices to manage collaboration, ensure code quality, and automate testing, documentation, and release processes. The infrastructure we built mirrors real-world open-source Python projects and helped us understand how professional development workflows operate."
  },
  {
    "objectID": "tools_infrastructure.html#version-control-and-collaboration",
    "href": "tools_infrastructure.html#version-control-and-collaboration",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Version Control and Collaboration",
    "text": "Version Control and Collaboration\nWe used Git and GitHub as our primary tools for version control and team collaboration. All development work was carried out using feature branches. We followed a Git Flow–inspired branching strategy:\n\nFeature branches for individual tasks\n\nA development branch used as a staging area\n\nThe main branch representing the stable release\n\nAll pull requests were first merged into the development branch. After integration and testing in development, changes were merged into main. This approach reduced the risk of breaking the stable branch and allowed multiple team members to work in parallel.\nGitHub Issues were used to track tasks, TA feedback, and peer review suggestions. Issues were linked to pull requests to maintain traceability between discussions and code changes."
  },
  {
    "objectID": "tools_infrastructure.html#continuous-integration-ci",
    "href": "tools_infrastructure.html#continuous-integration-ci",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Continuous Integration (CI)",
    "text": "Continuous Integration (CI)\nWe implemented automated CI using GitHub Actions. Our main CI workflow runs on pushes and pull requests and performs the following checks:\n\nInstalls the package with development, testing, and documentation dependencies\n\nRuns ruff for code style and linting\n\nExecutes the full test suite using pytest\n\nMeasures test coverage and uploads coverage reports to Codecov\n\nThis ensures that all contributions maintain functionality and follow coding standards before being merged."
  },
  {
    "objectID": "tools_infrastructure.html#documentation-infrastructure",
    "href": "tools_infrastructure.html#documentation-infrastructure",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Documentation Infrastructure",
    "text": "Documentation Infrastructure\nDocumentation for our package is built using Quarto and quartodoc. We maintain a documentation website that includes tutorials, function references, and project information.\nOur documentation pipeline includes:\n\nquartodoc build to generate function reference documentation\n\nquarto render to build the website\n\nWe use GitHub Actions to automatically build documentation and deploy it to the gh-pages branch. This keeps the documentation site synchronized with the latest stable version of the project without requiring manual updates.\nFor pull requests, a preview build of the documentation is generated and deployed to Netlify, allowing contributors to review documentation changes before merging."
  },
  {
    "objectID": "tools_infrastructure.html#automated-release-pipeline",
    "href": "tools_infrastructure.html#automated-release-pipeline",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Automated Release Pipeline",
    "text": "Automated Release Pipeline\nWe use an automated publishing workflow to simulate a professional Python package release process.\nOur release pipeline includes:\n\nBuilding the package using hatch\n\nRunning tests before release\n\nPublishing the package to TestPyPI automatically when changes are pushed to the main branch\n\nThis introduces semantic versioning practices and ensures that releases are reproducible and consistent."
  },
  {
    "objectID": "tools_infrastructure.html#code-quality-and-testing-practices",
    "href": "tools_infrastructure.html#code-quality-and-testing-practices",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Code Quality and Testing Practices",
    "text": "Code Quality and Testing Practices\nWe enforced several practices to maintain high code quality:\n\nUnit tests covering core functionality\n\nCoverage reporting to track test completeness\n\nLinting using ruff to enforce consistent style\n\nContinuous integration to detect issues early\n\nThese practices helped us prevent regressions and improve maintainability."
  },
  {
    "objectID": "tools_infrastructure.html#scaling-the-project",
    "href": "tools_infrastructure.html#scaling-the-project",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Scaling the Project",
    "text": "Scaling the Project\nIf this project were to scale into a larger or long-term software project, we would further enhance our infrastructure by:\n\nAdding branch protection rules to require CI checks before merging\n\nIntroducing pre-commit hooks for local linting and formatting\n\nExpanding test coverage and adding integration tests\n\nUsing automated dependency update tools (e.g., Dependabot)\n\nAutomating changelog generation and version management\n\nThese tools and practices would improve reliability, maintainability, and collaboration in a larger team setting."
  },
  {
    "objectID": "tools_infrastructure.html#reflection",
    "href": "tools_infrastructure.html#reflection",
    "title": "Tools, Infrastructure, and Development Practices",
    "section": "Reflection",
    "text": "Reflection\nThrough this project, we learned how modern software development integrates version control, CI/CD, documentation automation, and structured collaboration. These tools not only improve code quality but also support effective teamwork and reproducibility, which are essential in professional data science and software engineering environments."
  }
]